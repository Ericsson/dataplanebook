
<!DOCTYPE html>

<html lang="en_US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Statistics &#8212; Data Plane Software Design 0.0.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Timekeeping" href="../time.html" />
    <link rel="prev" title="Data Structures" href="../datastructures.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="statistics">
<span id="id1"></span><h1>Statistics<a class="headerlink" href="#statistics" title="Permalink to this headline">¶</a></h1>
<p><em>Section author: Mattias Rönnblom &lt;<a class="reference external" href="mailto:mattias&#46;ronnblom&#37;&#52;&#48;ericsson&#46;com">mattias<span>&#46;</span>ronnblom<span>&#64;</span>ericsson<span>&#46;</span>com</a>&gt;</em></p>
<p>The topic of this chapter is operational statistics for the data plane
<a class="reference internal" href="../glossary.html#term-Fast-path"><span class="xref std std-term">fast path</span></a>.</p>
<p>Data plane statistics provides information on events having occurred
in the data plane application. The same mechanism may also provide a
view into the current state of the data plane. The former is the focus
of this chapter.</p>
<p>The statistics of this chapter serves no purpose for the function the
data plane application provides. In other words, would the statistics
be removed, the user data would still flow through the network as
before.</p>
<p>The statistics are usually a direct result of fast path packet
processing (e.g., counters updated on a per-packet basis). There are
also counters in the slow path (assuming such a component
exists). Often, the slow path and fast path statistics need to be
merged in order to provide a consistent view of the data plane as a
whole.</p>
<p>Slow path statistics are more straight-forward to implement, since the
performance requirements are less stringent, and are out of scope for
this chapter.</p>
<section id="counters">
<h2>Counters<a class="headerlink" href="#counters" title="Permalink to this headline">¶</a></h2>
<p>In a <a class="reference internal" href="../glossary.html#term-SNMP"><span class="xref std std-term">SNMP</span></a> <a class="reference internal" href="../glossary.html#term-MIB"><span class="xref std std-term">MIB</span></a>, <em>counters</em> are non-negative integers
that monotonically increase, until they wrap upon exceeding some
maximum value (usually 2^32-1 or 2^64-1). A <em>gauge</em> is a non-negative
integer that varies within some predefined range.</p>
<p>For simplicity, this chapter uses the term <em>counter</em> to include both
what SNMP calls <em>counter</em> and what SNMP calls <em>gauge</em>. In practice,
the counter is the more common of the two.</p>
<p>In addition to counters, there may also be pseudo statistics
representing the current state of the data plane, rather than a
summary of past events. What type is best used to represent such state
varies; it may be a boolean, an integers or a string. The <a class="reference external" href="https://www.rfc-editor.org/rfc/rfc2578.txt">Structure
of Management Information (SMI)</a> - the SNMP MIB meta
model - allows for a number of other types, such as <em>Unsigned32</em>,
<em>TimeTicks</em> and <em>IpAddress</em>. Some of the techniques discussed in this
chapter also apply for managing and presenting state information to
external parties (e.g., the control plane).</p>
<p>There exist a wide variety of network management protocols to access
statistics-type information, where SNMP is just one among many. The
mechanism to access statistics from outside the <a class="reference internal" href="../glossary.html#term-Fast-path"><span class="xref std std-term">fast path</span></a>
process, and the data plane application, will be discussed in a future
chapter on control plane interfaces.</p>
<p>Although the available counters and their semantics are likely crafted
to fit some management plane data model (to avoid complex
transformations), the data plane fast path level implementation should
be oblivious to what entities access the data and for what purpose,
and what protocols are being used.</p>
</section>
<section id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Permalink to this headline">¶</a></h2>
<p>Data plane statistics can be used for a number of different purposes,
including:</p>
<ul class="simple">
<li><p>Troubleshooting and debugging</p></li>
<li><p>Node and network level performance monitoring and profiling</p></li>
<li><p>Security (e.g., detecting intrusion attempts)</p></li>
<li><p>In-direct functional uses (e.g., billing)</p></li>
</ul>
<p>The vague <em>in-direct functional use</em> means that while the counters
have no role in the local data plane function, they still serve a
purpose for the network as a whole. The counters may for example be
used for billing, or as input for automated or manual network
optimization.</p>
<section id="telemetry">
<h3>Telemetry<a class="headerlink" href="#telemetry" title="Permalink to this headline">¶</a></h3>
<p>Data plane statistics can be used as basis for network <em>telemetry</em>.
Telemetry means network nodes provides statistics to a central
location, usually using a push model. This information may then in
turn be used to address one or more of the above-mentioned use
cases. The data plane statistics implementation need not and should
not know if its statistics is being used for telemetry.</p>
</section>
</section>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<p>There are a number of aspects to consider, when specifying
requirements for fast path statistics:</p>
<ul class="simple">
<li><p>Performance</p></li>
<li><p>Correctness</p></li>
<li><p>Propagation delay</p></li>
<li><p>Time correlation</p></li>
<li><p>Consistency across multiple counters</p></li>
<li><p>Counter Reset</p></li>
<li><p>Writer parallelism</p></li>
<li><p>Reader preemption safety, read frequency, and acceptable read-side
cost</p></li>
</ul>
<section id="performance">
<h3>Performance<a class="headerlink" href="#performance" title="Permalink to this headline">¶</a></h3>
<section id="time-efficiency">
<span id="id2"></span><h4>Time Efficiency<a class="headerlink" href="#time-efficiency" title="Permalink to this headline">¶</a></h4>
<p>The typical data plane application has a range from a couple of
hundred clock cycles worth of <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a> per packet
for <a class="reference internal" href="../glossary.html#term-Low-touch-application"><span class="xref std std-term">low touch</span></a> applications, up to an
average of a couple of tens of thousands per packet for <a class="reference internal" href="../glossary.html#term-High-touch-application"><span class="xref std std-term">high
touch</span></a> applications.</p>
<p>Statistics are useful in almost all applications, and supporting a
reasonably large set of data plane counters is essential. In the light
of this, it makes sense to allocate a chunk of the fast path cycle
budget to spend on solving the statistics problem. On the other hand,
the fewer cycles spent on any per-packet task the better. The primary
business value of the data plane comes from the core data plane
function, and only a small minority of the CPU cycles should be spent
on statistics - an auxiliary function.</p>
<p>The number of counters updated per packet will range from somewhere
around a handful for low latency, low touch applications, up into the
hundreds for a complex, multi-layer protocol stack.</p>
<p>One seemingly reasonable assumption is that low touch and high touch
applications spend roughly the same amount of <a class="reference internal" href="../glossary.html#term-Domain-logic"><span class="xref std std-term">domain logic</span></a> CPU
cycles for every counter they need to update. The more elaborate
logic, the more cycles are spent, and the more there is a need to
account for what is going on, in order to, for example, profile or
debug the application, or the network. <a class="footnote-reference brackets" href="#cyclesvslogic" id="id3">1</a> Thus
a high touch application tend to update more counters per packet
than does its low touch cousin.</p>
<p>The next assumption is that no more than 5% of the total per-packet
CPU cycle budget should be spent on statistics, and that roughly one
counter update per 300 CPU cycles worth of domain logic
<a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a> is expected.</p>
<p>In case these assumptions hold true, the <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a>
budget for a counter update is 15 core clock cycles.</p>
<p>Uncertainties aside, this approximation give you an order-of-magnitude
level indication of the performance requirements, and underscores the
need to pay attention to producer-side statistics performance.</p>
<p>As an example of how things may go wrong if you don’t, consider an
application with a budget of 5000 clock cycles per packet and a
requirement for an average of 25 counter updates per packet. If the
development team goes down the <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a>
path, the statistics feature alone will consume several order of
magnitudes more than the budget <em>for the whole application</em>, assuming
the fast path is allocated to a handful of cores or more.</p>
<section id="vector-processing">
<h5>Vector Processing<a class="headerlink" href="#vector-processing" title="Permalink to this headline">¶</a></h5>
<p>If the fast path processing is organized as per the <a class="reference internal" href="../glossary.html#term-Vector-packet-processing"><span class="xref std std-term">vector
packet processing</span></a> design pattern, the
counter update overhead can potentially be reduced.</p>
<p>For example, if the lcore worker thread is handed a vector of 32
packets by the <a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduler</span></a>, all destined for Example
Protocol-level processing, the <code class="docutils literal notranslate"><span class="pre">total_pkts</span></code> need only be updated
once.</p>
</section>
</section>
<section id="space-efficiency">
<span id="id4"></span><h4>Space Efficiency<a class="headerlink" href="#space-efficiency" title="Permalink to this headline">¶</a></h4>
<p>It’s not unusual to see data plane applications which track (or
otherwise manage) large amounts of some kind of flows. Such flows may
be TCP connections, HTTP connections, PDCP bearers, IPsec tunnels, or
GTP-U tunnels, or indeed not really flows at all, like <a class="reference internal" href="../glossary.html#term-UE"><span class="xref std std-term">UEs</span></a> or known IP hosts. Often, it makes sense to have counters on a
per-flow basis. If the number of flows is large, the amount of memory
used to store counter state will be as well. In such applications,
care must be take to select a space efficient-enough statistics
implementation.</p>
<p>There are two sides to statistics memory usage. One is the amount of
memory allocated. The other is <a class="reference internal" href="../glossary.html#term-Working-set-size"><span class="xref std std-term">working set size</span></a>, and the
spatial (how tightly packed the data is) and temporal locality (how
quickly the same cache line is reused) of the memory used, which
affects <a class="reference internal" href="#time-efficiency"><span class="std std-ref">Time Efficiency</span></a>.</p>
<p>The former may impact requirements for the amount of DDR installed on
the system (or allocated to the container), and the amount of
<a class="reference internal" href="../glossary.html#term-Huge-Pages"><span class="xref std std-term">huge page</span></a> memory made available to the fast path
process.</p>
<p>The latter translate to CPU core stalls (waiting for memory to be read
or written), and thus more CPU cycles required per counter update, and
potentially more CPU cycles for the execution of other part of the
fast path, because statistics processing-generated cache pressure. The
more different counters are updated, the larger the <a class="reference internal" href="../glossary.html#term-Working-set-size"><span class="xref std std-term">working set
size</span></a> for the application as a whole.</p>
<p>Counters should not be evicted from the last level cache, with
often-used counters held in the L1 or L2 caches.</p>
<p>An issue strictly tied to space efficiency is the amount of DRAM
required to hold the statistics data structures. Depending on how the
counters are organized in memory, only a very small fraction of the
memory allocated may actually be used.</p>
<p>A related question is if memory consumption are required to correlate
with the number of active flows, or if it is acceptable to statically
preallocated statistics memory for the maximum number of flows
supported.</p>
<p>Prototyping may be required to determined how the counter
<a class="reference internal" href="../glossary.html#term-Working-set-size"><span class="xref std std-term">working set size</span></a> affects performance, both of the statistics
related operations, and other processing. For example, the per-core
counters are usually much more efficient than using a shared
statistics. However, if the shared data structure avoid last level
cache evictions, but it turns out the per-core counter approach
doesn’t, the shared approach may surpass per-core counters in
cycle-per-update performance, as well as requiring less memory. Cache
effects are notoriously difficult to prototype, in part since usually,
at the time of prototyping, the real network stack <a class="reference internal" href="../glossary.html#term-Domain-logic"><span class="xref std std-term">domain
logic</span></a> and the rest of the fast path is not yet in place.</p>
</section>
<section id="flow-affinity">
<h4>Flow Affinity<a class="headerlink" href="#flow-affinity" title="Permalink to this headline">¶</a></h4>
<p>An aspect to consider when choosing statistics implementation for
per-flow counters is whether or not the <a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduler</span></a> employed
in the fast path maintains flow-to-core affinity.</p>
<p>The affinity need not to be completely static, in the sense a flow
need not be pinned to a lcore worker forever until a system crash or
the heat death of the universe (whichever comes first) occurs.
Rather, it’s sufficient if a packet pertaining to a certain flow
<em>usually</em> go to the same worker core as the packet preceding it, in
that flow.</p>
<p>Flow affinity reduces statistics processing overhead regardless of
implementation, but applications with shared per-flow counters gain
the most.</p>
<p>Flow affinity makes it likely statistics related data is in a CPU
cache near the core. If, on the other hand, there is no affinity, the
cache lines holding the statistics data may well be located in a
different core’s private cache (having just been written to),
resulting in a very expensive cache miss when being accessed. Other
flow-related data follow the same pattern, resulting in affinity
generally having a significant positive effect on overall fast path
performance.</p>
</section>
<section id="parallel-flow-processing">
<h4>Parallel Flow Processing<a class="headerlink" href="#parallel-flow-processing" title="Permalink to this headline">¶</a></h4>
<p>Another important aspect to consider for per-flow counters is whether
or not packets pertaining to a particular flow are processed in
parallel. If a large flow is spread across multiple cores, the
<a class="reference internal" href="#shared-atomic-counters"><span class="std std-ref">shared atomic</span></a> and <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">shared lock
protected</span></a> approaches will suffer
greatly, as all worker cores fight to retrieve the same lock, or
otherwise access the same cache lines.</p>
<p>Usually, the data plane fast path includes some non-flow (e.g., global
or per-interface) counters, so the issue with high contention counters
need to be solved regardless.</p>
</section>
</section>
<section id="update-propagation-delay">
<h3>Update Propagation Delay<a class="headerlink" href="#update-propagation-delay" title="Permalink to this headline">¶</a></h3>
<p><em>Update propagation delay</em> in this chapter refers to the
<a class="reference internal" href="../glossary.html#term-Wall-clock-Latency"><span class="xref std std-term">wall-clock latency</span></a> between the point in time when the counted
event occurred, until the counter is updated and available to a
potential reader. The result of <a class="reference internal" href="../glossary.html#term-Domain-logic"><span class="xref std std-term">domain logic</span></a> processing that
caused the counter update (e.g, a packet being modified), and the
counter update itself, are never presented in an atomic manner to the
parties outside the fast path process. This would imply that somehow
the delivery of packets from the data plane and the delivery of
counter updates to the external world could be done atomically.</p>
<p>The counter implementation patterns presented in this chapter, unless
otherwise mentioned, all have a very short update propagation
delay. It boils down to the time it takes for the result of a CPU
<a class="reference internal" href="../glossary.html#term-Store"><span class="xref std std-term">store</span></a> instruction become globally visible. This process
shouldn’t take more than a couple of hundred nanoseconds, at most.</p>
<p>One way to reason about update propagation delay requirements is to
think about how quickly a user, or any kind of data plane
application-external agent, could retrieve counters which should
reflect a particular packet having been received, processed, or sent.</p>
<p>For example, if serving a control plane request has a practical
(although not guaranteed) lower <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a> of 1 ms,
that could be used to set an upper boundary for the counter update
propagation delay.</p>
</section>
</section>
<section id="organization">
<h2>Organization<a class="headerlink" href="#organization" title="Permalink to this headline">¶</a></h2>
<p>A common and straightforward way of organizing counters are as one or
more nested C structs. Addressing an individual counter in a C struct
is very efficient, since the offset, in relation to the beginning of
the struct, is known at compile time.</p>
<p>An issue with C structs is that the maximum cardinality of the various
objects (e.g., interfaces, routes, flow, connections, users, bearers)
must be known at compile time. The struct may become very large when
dimensioned for the worst case, for every type of object. Spatial
locality may also be worse than other, more compact, alternatives.</p>
<p>An alternative to structs is to use some kind of map, for example a
hash table or some sort of tree. However, even efficient map
implementations typically has a <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a> in the
range 10-100s of clock cycles to access the value of a key.</p>
<p>One radically different approach to managing counters is to maintain
only changes, and not the complete statistics state, in the data plane
fast path application. The aggregation of the changes are either done
in a <a class="reference internal" href="../glossary.html#term-Data-plane-control"><span class="xref std std-term">data plane control</span></a> process or thread, or in the control
plane proper. See <a class="reference internal" href="#shared-counters-with-per-core-buffering"><span class="std std-ref">Shared Counters with Per Core Buffering</span></a> for
more on this.</p>
<p>The statistics can either be organized in a global statistics database
for the whole fast path, or broken down per module, or per layer
basis, resulting in many different memory blocks being used.</p>
<p>In case of the global statistics struct type, care must be taken not
to needlessly couple different protocol modules via the statistics
module. On the statistics consumer side on the other hand, it might
make perfect sense to see all statistics, for all the different parts
of the data plane fast path.</p>
<p>Please note that the above discussion is orthogonal to the question
whether or not the statistics data type should be kept in a single
instance (or an instance per module, in the modularized case), or an
instance per lcore.</p>
<section id="separate-versus-integrated-counters">
<h3>Separate versus Integrated Counters<a class="headerlink" href="#separate-versus-integrated-counters" title="Permalink to this headline">¶</a></h3>
<p>A design decision to make is if the counters should be an integral
part of other network stack state, or kept separate (possibly together
with statistics from other modules).</p>
<p>For example, consider an application that has a notion of a flow, a
connection, an interface, a port, or a session. It keeps state related
to the processing of packets pertaining to such domain-level objects
in some data structure.</p>
<p>One option is to keep the counter state produced as a side effect of
the network stack <a class="reference internal" href="../glossary.html#term-Domain-logic"><span class="xref std std-term">domain logic</span></a> processing in the same struct
as the core domain logic state. In case the domain logic state is
protected by a lock, the counter updates could be performed under the
protection of the same lock, at very little additional cost, provided
the counters belongs to that object (as opposed to counters related
to some aggregate of such objects, or global counters).</p>
<p>A potential reader would use the same lock to serialize access to the
counters. This would be an implementation of the <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> pattern, with per-flow locks. Non-flow counters
would be handled separately.</p>
<p>There are also hybrids, where the statistics is an integral part of
the domain logic data structures, but the statistics synchronization
is done differently compared to accesses of domain object state.</p>
<p>The example implementations in this chapter use a simple,
self-contained, fix size, statically allocated struct, but the various
pattern applies to more elaborate, dynamically allocated data
structures as well.</p>
<p>One way to reduce the amount of memory used (or at least make the
amount of memory used be in relation to the data plane application’s
configuration) for systems with high max cardinality, and large
variations in the number of actual objects instantiated, is to use
dynamic allocation, but use fixed-offset accesses to the fields within
those dynamically-allocated chunks of memory. For example, the list of
flows could be a pointer to a dynamically allocated array, instead of
a fixed, compile-time-sized, array.</p>
<p>Large counter data structures should be allocated from <a class="reference internal" href="../glossary.html#term-Huge-Pages"><span class="xref std std-term">huge
page</span></a> memory, regardless if the statistics struct is
self-contained or spread across many different chunks of memory.</p>
</section>
</section>
<section id="synchronization">
<h2>Synchronization<a class="headerlink" href="#synchronization" title="Permalink to this headline">¶</a></h2>
<p>This chapter describes a number of approaches to counter
implementation, with a focus on writer-writer synchronization (i.e.,
synchronization between different lcore worker threads updating the
same counter) and reader-writer synchronization (e.g., synchronization
between the <a class="reference internal" href="../glossary.html#term-Control-thread"><span class="xref std std-term">control threads</span></a> and the lcore
workers).</p>
<p>In case where a data plane application has only one lcore worker
thread, or there are multiple lcore workers, but there is no overlap
between what counters the different threads manipulate in parallel,
there is no need for writer-writer synchronization. The only concern
in this case, is reader-writer synchronization, assuming there is a
separate reader thread (e.g., a <a class="reference internal" href="../glossary.html#term-Control-thread"><span class="xref std std-term">control thread</span></a>). The solution
to the reader problem can be solved in the same way as is described in
the section for <a class="reference internal" href="#per-core-counters"><span class="std std-ref">Per Core Counters</span></a>.</p>
<p>The different patterns described in this section assumes multiple
lcore workers with in part or fully overlapping statistics, and one or
more separate reader threads.</p>
<p>Below are the data structure definition and declarations for the
fictitious Example Protocol (EP). EP has packets and flows, and
counters on both a global level, and on a per-flow basis.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#define EP_MAX_SESSIONS (1000)</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="n">sessions</span><span class="p">[</span><span class="n">EP_MAX_SESSIONS</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="n">stats</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>Needless to say, a real application will have a more counters,
organized into more struct types.</p>
<section id="shared-non-synchronized-counters">
<span id="id5"></span><h3>Shared Non Synchronized Counters<a class="headerlink" href="#shared-non-synchronized-counters" title="Permalink to this headline">¶</a></h3>
<p>One approach to counter synchronization is to ignore the issue
altogether. The responsible architect might mumble something about
<a class="reference internal" href="../glossary.html#term-Load"><span class="xref std std-term">loads</span></a> and <a class="reference internal" href="../glossary.html#term-Store"><span class="xref std std-term">stores</span></a> up to 64-bits always
being atomic on modern architectures, and that there’s no need to
worry too much about the occasional miscount, since it’s “just
statistics”.</p>
<p>This approach is disastrous in terms of correctness and performs
poorly - a less than ideal combination.</p>
<p>In order for an lcore worker thread to increment a counter, it will
just call the update function, which in turn will do a normal
C integer addition.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">	    </span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">stats</span><span class="p">.</span><span class="n">total_pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">stats</span><span class="p">.</span><span class="n">total_bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>GCC 10.3.0 compiling for a Cascade Lake generation x86_64 CPU will
generate this code:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ep_stats_update(unsigned int, unsigned short):
        movzx   esi, si
        mov     eax, 1
        vmovq   xmm1, rsi
        vpinsrq xmm0, xmm1, rax, 1
        vpaddq  xmm0, xmm0, XMMWORD PTR stats[rip+16000]
        mov     edi, edi
        sal     rdi, 4
        inc     QWORD PTR stats[rdi+8]
        add     QWORD PTR stats[rdi], rsi
        vmovdqa XMMWORD PTR stats[rip+16000], xmm0
        ret
stats:
        .zero   16016
</pre></div>
</div>
<p>The inc and add instructions act directly against memory, which may
lead the unwary to believe everything is fine so far (which it isn’t,
since they lack the “lock” prefix, and thus are non-atomic).</p>
<p>However, the <code class="docutils literal notranslate"><span class="pre">vmovdqa</span></code> instruction makes it obvious there is a
problem here. A sequence consisting of a load from memory to register,
a register add, and a store to memory is always a race, in case
multiple core act on the same memory location without employing some
kind of external synchronization.</p>
<p>Here’s the same code compiled for the ARMv8-A <a class="reference internal" href="../glossary.html#term-ISA"><span class="xref std std-term">ISA</span></a>, with the
nice and tidy code generated by Clang 11.0.1:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ep_stats_update(unsigned int, unsigned short):                  // @ep_stats_update(unsigned int, unsigned short)
        adrp    x8, stats
        add     x8, x8, :lo12:stats
        ldr     x9, [x8, #16008]
        ldr     x10, [x8, #16000]
        add     x11, x8, w0, uxtw #4
        add     x9, x9, #1                      // =1
        str     x9, [x8, #16008]
        and     x9, x1, #0xffff
        add     x10, x10, x9
        str     x10, [x8, #16000]
        ldp     x10, x8, [x11]
        add     x8, x8, #1                      // =1
        add     x9, x10, x9
        stp     x9, x8, [x11]
        ret
stats:
        .zero   16016
</pre></div>
</div>
<p>This approach, as implemented in the benchmark application described
in <a class="reference internal" href="#performance-comparison"><span class="std std-ref">Performance Comparison</span></a> and running on four Cascade Lake
x86_64 cores, loses a whopping ~18% of the global packet count updates
when the fast path is running at max capacity.</p>
</section>
<section id="shared-atomic-counters">
<span id="id6"></span><h3>Shared Atomic Counters<a class="headerlink" href="#shared-atomic-counters" title="Permalink to this headline">¶</a></h3>
<p>The correctness issue with <a class="reference internal" href="#shared-non-synchronized-counters"><span class="std std-ref">Shared Non Synchronized Counters</span></a> can
easily be addressed by using an <em>atomic</em> add for the counter producer
and an <em>atomic</em> <a class="reference internal" href="../glossary.html#term-Load"><span class="xref std std-term">load</span></a> for the consumer side.</p>
<p>In this solution, there is only a single instance of the statistics
struct, accessed by using atomic instructions.</p>
<section id="arithmetic-operations">
<h4>Arithmetic Operations<a class="headerlink" href="#arithmetic-operations" title="Permalink to this headline">¶</a></h4>
<p>Below is the <code class="docutils literal notranslate"><span class="pre">ep_stats_update()</span></code> function updated to use atomic
operations:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">	    </span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">__atomic_fetch_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">			   </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">__atomic_fetch_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">,</span><span class="w"></span>
<span class="w">			   </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">__atomic_fetch_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">			   </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">__atomic_fetch_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">,</span><span class="w"></span>
<span class="w">			   </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="reading">
<h4>Reading<a class="headerlink" href="#reading" title="Permalink to this headline">¶</a></h4>
<p>Reading counter values is very straight-forward and <a class="reference internal" href="../glossary.html#term-Preemption-Safety"><span class="xref std std-term">preemption
safe</span></a>:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_session_read</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"></span>
<span class="w">		      </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">result</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__atomic_load_n</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"></span>
<span class="w">				       </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__atomic_load_n</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"></span>
<span class="w">					</span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>The use of atomic loads does not impact performance, but does
guarantee that the read is atomic. Naturally aligned <a class="reference internal" href="../glossary.html#term-Load"><span class="xref std std-term">load</span></a>
operations up to 64-bit are atomic on all modern CPU
architectures. However, a non-atomic access allows the compiler to
divide a 64-bit load, for example, into two 32-bit loads, which in
turn allows for a counter update to sneak in between the loads,
wreaking havoc with correctness.</p>
</section>
<section id="reset">
<h4>Reset<a class="headerlink" href="#reset" title="Permalink to this headline">¶</a></h4>
<p>A counter read can be combined with a counter reset by using an atomic
exchange operation.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_session_reset</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"></span>
<span class="w">		       </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">result</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__atomic_exchange_n</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">					   </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__atomic_exchange_n</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">					    </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>This approach does not guarantee consistency across multiple, related
counters, since atomicity guarantees are only for a single
counter. For example, a lcore worker may have incremented the session
<code class="docutils literal notranslate"><span class="pre">pkts</span></code> before the reset was performed by the control thread, and the
<code class="docutils literal notranslate"><span class="pre">total_pkts</span></code> updates happens after the reset.</p>
<p>Resetting the counters from the reader thread by first reading the
current value with an atomic read, followed by an atomic store of 0,
may lead to counter changes to be lost, since combined, those two
operations are no atomic.</p>
</section>
<section id="inter-counter-consistency">
<h4>Inter Counter Consistency<a class="headerlink" href="#inter-counter-consistency" title="Permalink to this headline">¶</a></h4>
<p>Shared atomic counters does not guarantee atomicity across multiple
counters. Thus, a reader might see a <code class="docutils literal notranslate"><span class="pre">total_bytes</span></code> which has been
updated with the length of a certain packet, but a <code class="docutils literal notranslate"><span class="pre">total_pkts</span></code>
which value does not reflect that particular packet being processed.</p>
<p>The relaxed C11 memory model (<code class="docutils literal notranslate"><span class="pre">__ATOMIC_RELAXED</span></code>) is used, which
means that the reader might see the updates in a different order than
the <a class="reference internal" href="../glossary.html#term-Program-order"><span class="xref std std-term">program order</span></a>. For counters, this does not create any
additional issues. The reader will prefer to see a consistent view of
the statistics, but performing the updates in a particular,
well-defined order (using a different C11 memory model), does not
help.</p>
</section>
<section id="id7">
<h4>Performance<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>Shared atomic counters perform well if there is little or no
contention on the cache line where the counters reside. For counters
that are updated frequently (e.g., for every packet) by multiple CPU
cores, shared atomic counters performs poorly, because of the costly
cache line ownership transfers incurred.</p>
</section>
</section>
<section id="shared-lock-protected-counters">
<span id="id8"></span><h3>Shared Lock Protected Counters<a class="headerlink" href="#shared-lock-protected-counters" title="Permalink to this headline">¶</a></h3>
<p>Another way to extend the <a class="reference internal" href="#shared-non-synchronized-counters"><span class="std std-ref">Shared Non Synchronized Counters</span></a>
approach into something that actually works is to do the obvious: add
a lock.  The lock would be used to serialize both writer and reader
access. A per-module statistics lock is used in the example. A more
fine-grained locking (e.g., per-flow locks) strategy is possible, and
depending on how <a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduling</span></a> is
implemented, this may yield some performance benefits.</p>
<p>If this pattern is used, the statistics struct is supplemented with a
<a class="reference internal" href="../glossary.html#term-Spinlock"><span class="xref std std-term">spinlock</span></a>:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="n">stats</span><span class="p">[</span><span class="n">RTE_MAX_LCORE</span><span class="p">];</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="n">rte_spinlock</span><span class="w"> </span><span class="n">stats_lock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">RTE_SPINLOCK_INITIALIZER</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>The above example keeps the lock separate from the data, but the lock
may also be added to the struct itself. Co-locating the lock with
often-used (e.g., global) counters may yield a slight performance
benefit. However, if the struct is used elsewhere in the program
(e.g., in <a class="reference internal" href="../intro.html#data-plane-control"><span class="std std-ref">data plane control</span></a>), to pass
around statistics, including the lock may not make sense.</p>
<p>A spinlock is preferred over a POSIX thread mutex, since in the case a
pthread mutex is taken at the point a thread is attempting to acquire
it, the thread is put to sleep by the kernel. A process context is
very costly, and putting DPDK lcore worker threads to sleep usually
doesn’t make sense <a class="footnote-reference brackets" href="#sleep" id="id9">2</a>.</p>
<p>For improved fairness, a ticket lock could be used in place of the
spinlock.</p>
<p>Fine-grained parallelism allows for more parallelism (see
<a class="reference internal" href="../glossary.html#term-Amdahl-s-law"><span class="xref std std-term">Amdahl’s law</span></a>), but the overhead of many acquire and release
operations may turn gains into losses.</p>
<p>Generally, in user space applications, the primary cause of the
performance degradation caused by a lock is related to the length (in
terms of <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing latency</span></a>) of the <a class="reference internal" href="../glossary.html#term-Critical-section"><span class="xref std std-term">critical section</span></a>
(i.e., how long the lock is held). For the category of
short-transaction systems that data plane applications fall into, the
main issue is usually not critical section length - since it’s usually
very short - but rather the lock-related overhead. This overhead
becomes significant in high-contention cases.</p>
<p>So, even though the critical section is just a load, an add, and a
store machine instruction (or something along those lines), the lock
may cause significant overhead.</p>
<section id="id10">
<h4>Arithmetic Operations<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>Adding to one or more counters is only a matter of taking the lock,
and perform whatever operations are required, after which the
lock is released.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">	    </span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_spinlock_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">stats</span><span class="p">.</span><span class="n">total_pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">stats</span><span class="p">.</span><span class="n">total_bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_spinlock_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="id11">
<h4>Reading<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<p>Reading counter values is very straight-forward, but <em>not</em>
<a class="reference internal" href="../glossary.html#term-Preemption-Safety"><span class="xref std std-term">preemption safe</span></a>. In case the reader thread
is preempted when it has acquired the lock, but not yet released it,
all the lcore worker threads will eventually be waiting to acquire the
lock, and will continue to make progress only when the reader thread
is re-scheduled and may continue processing and release the lock.</p>
<p>Thus, care must be taken that the <a class="reference internal" href="../glossary.html#term-Control-thread"><span class="xref std std-term">control thread</span></a> (or some
other reader) is not preempted, at least not for any long duration of
time.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_session_read</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"></span>
<span class="w">		      </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">result</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_spinlock_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_spinlock_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>The above example includes acquiring and releasing the lock as a part
of the access function. Another option is to have explicit reader lock
and release functions in the <code class="docutils literal notranslate"><span class="pre">ep_stats.h</span></code> API. In that case, a
reader may read a large amount of counters, without taking the
overhead for a large number of lock and unlock calls.</p>
</section>
<section id="id12">
<h4>Reset<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<p>The transactional nature of accessing the statistics that the lock
enables makes supporting counter reset trivial, including maintaining
consistency across multiple, related counters.</p>
<p>One option is to add a separate read-and-reset function, like the
<code class="docutils literal notranslate"><span class="pre">ep_stats_session_reset</span></code> from the <a class="reference internal" href="#shared-atomic-counters"><span class="std std-ref">Shared Atomic Counters</span></a>.</p>
<p>Another option is to use explicit locking for reader (or, for reader
<em>and</em> writer) statistics access. In that case, a <a class="reference internal" href="../glossary.html#term-Control-thread"><span class="xref std std-term">control
thread</span></a> wanting to reset all, or a subset of, the statistics would:</p>
<ol class="arabic simple">
<li><p>Acquire the statistics lock</p></li>
<li><p>Optionally read out state of the statistics (prior to reset)</p></li>
<li><p>Store zeros to the counter variables</p></li>
<li><p>Release the statistics lock</p></li>
</ol>
<p>The implementation could look something like <a class="footnote-reference brackets" href="#id31" id="id13">3</a>:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_lock</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">rte_spinlock_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_unlock</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">rte_spinlock_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats_lock</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_reset</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">	    </span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="id14">
<h4>Inter Counter Consistency<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<p>A benefit with <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> is the ability to
support consistency cross an arbitrary number of counters. For
example, the <code class="docutils literal notranslate"><span class="pre">ep_stats_update()</span></code> function will guarantee that the
total and per-session packet count are updated atomically. A properly
implemented reader will never see data inconsistent in this regard.</p>
</section>
<section id="id15">
<h4>Performance<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<p>For counters which are incremented for most or all packets,
<a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> suffers from the same issue as
<a class="reference internal" href="#shared-non-synchronized-counters"><span class="std std-ref">Shared Non Synchronized Counters</span></a> and <a class="reference internal" href="#shared-atomic-counters"><span class="std std-ref">Shared Atomic Counters</span></a>.  Ownership of cache lines that holds the state of such
counters will bounce around between the worker lcores, causing CPU
core stalls and interconnect traffic in the process. For <a class="reference internal" href="../glossary.html#term-Low-touch-application"><span class="xref std std-term">low
touch applications</span></a>, this situation quickly
deteriorate as worker lcores are added to the system. In addition, the
lock forces more costly inter-core synchronization and a full (usually
implicit) memory barrier. This barrier is not present when
<a class="reference internal" href="#shared-atomic-counters"><span class="std std-ref">Shared Atomic Counters</span></a> are employed.</p>
<p><a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> is generally prohibitively slow
for counters incremented on a per-packet basis, or similar frequency.</p>
</section>
</section>
<section id="shared-counters-with-per-core-buffering">
<span id="id16"></span><h3>Shared Counters with Per Core Buffering<a class="headerlink" href="#shared-counters-with-per-core-buffering" title="Permalink to this headline">¶</a></h3>
<p>The primary performance issue with <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> is the high contention for the lock, or set of locks, that
protect counters that are frequently updated, from many or all lcore
worker cores.</p>
<p>One way to reduce statistics lock contention and amortize locking
overhead over multiple counter updates, is to introduce a per-lcore
counter update write buffer.</p>
<p>When the data plane fast path application domain logic asks to
increment a counter, no update is performed. Rather, the address of
the counter’s memory location, optionally the type (in case different
counters have different data types), and the operand is stored in a
buffer.</p>
<p>When the buffer is full, the statistics framework module will take the
lock and apply all changes. In case the system divides the statistics
memory on a per-module basis, several write buffers may be needed, or
alternatively a single lock may be used to protect the aggregation of
all statistics memory areas.</p>
<p>The number of machine instructions that need to be executed in this
implementation far exceed that of the other patterns described here.
For example, <a class="reference internal" href="#shared-atomic-counters"><span class="std std-ref">Shared Atomic Counters</span></a> likely only needs less than
a handful of machine instructions per counter update, compared to the
many instructions needed to store the changes in a buffer, and apply
the changes at a later time.</p>
<p>Nevertheless, this instruction-heavy pattern generally outperforms all
the other shared counter approaches, since it does not suffer from the
cache line ping-pong of the alternatives.</p>
<p>The realization of this pattern is more complex than the alternatives.
Thus, the introduction of a small statistics framework module to is
warranted, to manage this complexity. The API to such a framework
could look something like:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">stat_wb_schedule_add64</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">);</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">stat_wb_hint_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">stat_wb_try_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">stat_wb_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">stat_wb_schedule_add64()</span></code> function schedules a 64-bit add
operation to be performed at some point. In case the write buffer is
full at the point of the schedule call, it’s emptied and all the
buffered arithmetic operations therein are performed. This function
will be called, via a convenience wrapper, by the fast path
<a class="reference internal" href="../glossary.html#term-Domain-logic"><span class="xref std std-term">domain logic</span></a>, to increment a counter.</p>
<p>This minimal API presented here supports only 64-bit add operations,
but add operations with a smaller integer (or even floating point)
operand could well make sense to include, as well as a
<code class="docutils literal notranslate"><span class="pre">state_wb_schedule_sub64</span></code>, in case a counter is actually a gauge.</p>
<p>In case of gauges, an alternative approach is to change from
<code class="docutils literal notranslate"><span class="pre">uint64_t</span></code> to <code class="docutils literal notranslate"><span class="pre">int64_t</span></code>, and while there might exist an add
operation on the API layer, a subtraction is buffered (and applied) in
the form of an add with a negated operand, for improved flush
performance and spatial locality.</p>
<p><code class="docutils literal notranslate"><span class="pre">stat_wb_flush()</span></code> forces a flush of the buffer. This may be useful
to do either after a packet, after a batch of packets, or using a
timer, depending on how urgent it is for the updates to be visible to
a potential reader thread within the fast path process.</p>
<p><code class="docutils literal notranslate"><span class="pre">stat_wb_try_flush()</span></code> commences a non-blocking attempt to flush the
buffer.</p>
<p><code class="docutils literal notranslate"><span class="pre">state_wb_hint_flush()</span></code> is a function which may be called
periodically, for every batch of packets, which will eventually cause
the write buffer to be flush (every Nth call). This may be called for
every batch of packets (or work items) received from the NIC or a
<a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduler</span></a>, in case a flush for every batch is too
expensive. If it’s called for zero-sized batches as well, no flush
timer is needed.</p>
<p>Here follows an implementation of the <code class="docutils literal notranslate"><span class="pre">stat_wb.h</span></code> API:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#define STAT_WB_MAX_SIZE (1024)</span>
<span class="cp">#define STAT_WB_SOFT_THRESHOLD (STAT_WB_MAX_SIZE / 2)</span>
<span class="cp">#define STAT_WB_MAX_HINTS (64)</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb_add64_op</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">hints</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">num_add64_ops</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb_add64_op</span><span class="w"> </span><span class="n">add64_ops</span><span class="p">[</span><span class="n">STAT_WB_MAX_SIZE</span><span class="p">];</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="n">__rte_cache_aligned</span><span class="p">;</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="n">lcore_wbs</span><span class="p">[</span><span class="n">RTE_MAX_LCORE</span><span class="p">];</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="n">rte_spinlock_t</span><span class="w"> </span><span class="n">stat_lock</span><span class="w"> </span><span class="n">__rte_cache_aligned</span><span class="p">;</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="w"></span>
<span class="n">lcore_wb</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lcore_id</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">lcore_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rte_lcore_id</span><span class="p">();</span><span class="w"></span>
<span class="w">	</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lcore_wbs</span><span class="p">[</span><span class="n">lcore_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="n">wb</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"></span>
<span class="n">flush</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">force</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">force</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">STAT_WB_MAX_SIZE</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">rte_spinlock_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stat_lock</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">rte_spinlock_trylock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stat_lock</span><span class="p">))</span><span class="w"></span>
<span class="w">		</span><span class="k">return</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">		</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb_add64_op</span><span class="w"> </span><span class="o">*</span><span class="n">op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">add64_ops</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>

<span class="w">		</span><span class="o">*</span><span class="n">op</span><span class="o">-&gt;</span><span class="n">counter</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">op</span><span class="o">-&gt;</span><span class="n">operand</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="p">}</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_spinlock_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stat_lock</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">hints</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"></span>
<span class="n">try_flush</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">flush</span><span class="p">(</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"></span>
<span class="n">force_flush</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">flush</span><span class="p">(</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"></span>
<span class="n">schedule_add64</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter</span><span class="p">,</span><span class="w"></span>
<span class="w">	       </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">add64_ops</span><span class="p">[</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">	    </span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb_add64_op</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">		</span><span class="p">.</span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counter</span><span class="p">,</span><span class="w"></span>
<span class="w">		</span><span class="p">.</span><span class="n">operand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">operand</span><span class="w"></span>
<span class="w">	</span><span class="p">};</span><span class="w"></span>

<span class="w">	</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="n">stat_wb_schedule_add64</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lcore_wb</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">STAT_WB_MAX_SIZE</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">force_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">STAT_WB_SOFT_THRESHOLD</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">try_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">schedule_add64</span><span class="p">(</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">operand</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="n">stat_wb_hint_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lcore_wb</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">hints</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">STAT_WB_MAX_HINTS</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">try_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="k">else</span><span class="w"></span>
<span class="w">		</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">hints</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="n">stat_wb_try_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lcore_wb</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="n">try_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="n">stat_wb_flush</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lcore_wb</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="n">force_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>This implementation uses the DPDK pattern of keeping per-lcore data
structure in static array, sized in accordance to the maximum number
of lcores supported, and using the lcore id as an index into this
array. This is convenient and makes for a clean API, but does prohibit
any non-lcore worker threads from performing counter updates (a
non-lcore thread does not have an lcore id) via the write buffer.</p>
<section id="id17">
<h4>Arithmetic Operations<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h4>
<p>The use of the <code class="docutils literal notranslate"><span class="pre">stat_wb.h</span></code> API to increment a set of counters could
look like this:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">stat_wb_schedule_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">stat_wb_schedule_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">stat_wb_schedule_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">stat_wb_schedule_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>To slightly improve performance, primarily by amortizing the function
call overhead, and more importantly, the lcore id <a class="reference internal" href="../glossary.html#term-TLS"><span class="xref std std-term">TLS</span></a> lookup,
across multiple counter updates a multiple-counter update function may
be introduced:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">stat_wb_schedule_add64_m</span><span class="p">(</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">num_ops</span><span class="p">,</span><span class="w"> </span><span class="p">...)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">stat_wb</span><span class="w"> </span><span class="o">*</span><span class="n">wb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lcore_wb</span><span class="p">();</span><span class="w"></span>
<span class="w">	</span><span class="kt">va_list</span><span class="w"> </span><span class="n">ap</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="n">STAT_WB_MAX_SIZE</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_ops</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">force_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wb</span><span class="o">-&gt;</span><span class="n">num_add64_ops</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">STAT_WB_SOFT_THRESHOLD</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">try_flush</span><span class="p">(</span><span class="n">wb</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">va_start</span><span class="p">(</span><span class="n">ap</span><span class="p">,</span><span class="w"> </span><span class="n">num_ops</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_ops</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">		</span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter</span><span class="p">;</span><span class="w"></span>
<span class="w">		</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">;</span><span class="w"></span>

<span class="w">		</span><span class="n">counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">va_arg</span><span class="p">(</span><span class="n">ap</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="p">);</span><span class="w"></span>
<span class="w">		</span><span class="n">operand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">va_arg</span><span class="p">(</span><span class="n">ap</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="p">);</span><span class="w"></span>

<span class="w">		</span><span class="n">schedule_add64</span><span class="p">(</span><span class="n">wb</span><span class="p">,</span><span class="w"> </span><span class="n">counter</span><span class="p">,</span><span class="w"> </span><span class="n">operand</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="p">}</span><span class="w"></span>

<span class="w">	</span><span class="n">va_end</span><span class="p">(</span><span class="n">ap</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>This function allows incrementing multiple counters in one call. With
this addition to the <code class="docutils literal notranslate"><span class="pre">stat_wb.h</span></code> API, <code class="docutils literal notranslate"><span class="pre">ep_stats_update</span></code> could be
modified to use the new function:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">stat_wb_schedule_add64_m</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"></span>
<span class="w">			</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_pkts</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">			</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">total_bytes</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="n">pkt_size</span><span class="p">,</span><span class="w"></span>
<span class="w">			</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">			</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">)</span><span class="n">pkt_size</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Beyond the potential performance benefits, this function allows the
updates to be applied atomically against the global <code class="docutils literal notranslate"><span class="pre">ep_stats</span></code>
counter struct. For this to work, the write buffer buffer must be at
least the size of the largest counter update transaction.</p>
</section>
<section id="id18">
<h4>Reading<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h4>
<p>Reading counters is done in the same manner as in the <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> pattern.</p>
<p>Reader preemption safety is still a concern.</p>
</section>
<section id="id19">
<h4>Reset<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h4>
<p>For resetting counters, the developer is left with the same options as
in the <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> approach.</p>
</section>
<section id="id20">
<h4>Inter Counter Consistency<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h4>
<p>In terms providing a consistent view on a set of related counters, or
even all counters, the same opportunities as in <a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a> exist.</p>
</section>
<section id="id21">
<h4>Performance<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="#shared-counters-with-per-core-buffering"><span class="std std-ref">Shared Counters with Per Core Buffering</span></a> is space efficient,
while maintaining fairly good cycle efficiency, both for counters
which are primarily updated by one core, and counters which are
updated by many cores, at high frequencies.</p>
<p>An appropriately sized write buffer is important for characteristics,
and there are a number of forces that pull in different directions:</p>
<ul class="simple">
<li><p>A large buffer will increase the <a class="reference internal" href="../glossary.html#term-Working-set-size"><span class="xref std std-term">working set size</span></a> of the
application, potentially having a negative impact on performance,
primarily by causing the eviction of level 1 cache lines used by
other parts of the fast path.</p></li>
<li><p>If the same counter is repeatedly updated as a part of the same,
large, write buffer flush transaction, flush performance will
benefit from thes high degree of temporal locality.</p></li>
<li><p>A write buffer which are allowed to grow large will take the lcore
worker thread a long time to flush, potentially causing an unacceptable
level of packet latency jitter.</p></li>
<li><p>A small write buffer will cause high contention for the (per-module,
or global) statistics lock, reintroducing the very issue the write
buffer is there to solve.</p></li>
<li><p>A large write buffer, combined with the use of the
<code class="docutils literal notranslate"><span class="pre">stat_wb_try_flush()</span></code> function, can be used for mitigation in a
situation where a thread (e.g., another lcore worker thread, or a
<a class="reference internal" href="../glossary.html#term-Control-thread"><span class="xref std std-term">control thread</span></a>) holds the lock for a relatively long time.</p></li>
</ul>
<p>Moving the <code class="docutils literal notranslate"><span class="pre">stat_wb</span></code> functions, in particular the add function, to
the API header file may slightly improve the performance <a class="footnote-reference brackets" href="#nogain" id="id22">4</a> in
non-<a class="reference internal" href="../glossary.html#term-LTO"><span class="xref std std-term">LTO</span></a> builds, since then the function may be inlined by the
compiler.</p>
</section>
<section id="propagation-delay">
<h4>Propagation Delay<a class="headerlink" href="#propagation-delay" title="Permalink to this headline">¶</a></h4>
<p>Per-core buffering may introduce a noticeable delay between the
counted event occurring, and the time when the counter is updated and
the results are available to a potential reader.</p>
<p>In case the write buffer is not flushed, the execution of the buffered
add operations may be delayed indefinitely.</p>
<p>A simple and often effective model is to force a write buffer flush
for every batch of work items (e.g., packets) a lcore worker
process. In low-load situations, the lcore is usually asked by the
<a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduler</span></a> to process very few packets per batch. In that
situation, the statistics overhead will increase, since the flush
operation is performed with relatively few counter updates
buffered. However, the demand for the fast path to be CPU cycle
efficient is lower during low load. <a class="footnote-reference brackets" href="#nodemand" id="id23">5</a> During high load, the
lcore worker will start to experience larger batches, and counter
flushes will contain more operations, reducing per-counter update
overhead.</p>
<p>As an example, assume a fast path application where the processing is
organized as a pipeline, with a per-pipeline stage <a class="reference internal" href="../glossary.html#term-Processing-Latency"><span class="xref std std-term">processing
latency</span></a> of 1000 core clock cycles, running on a CPU operating at 2,5
GHz. When a batch of packets have been processed, the lcore calls
<code class="docutils literal notranslate"><span class="pre">stat_wb_flush()</span></code>. If only a single packet is being processed, the
delay introduced by buffering is at most ~400 ns. If a burst of
packets arrive, an the lcore is being handed 32 packets, the delay
will be less than ~13 us.</p>
</section>
</section>
<section id="per-core-counters">
<span id="id24"></span><h3>Per Core Counters<a class="headerlink" href="#per-core-counters" title="Permalink to this headline">¶</a></h3>
<p>In DPDK, per-core data structures (usually in the form of nested C
struct) are usually implemented by having as many instances of the
struct as the maximum number of support DPDK lcores
(<code class="docutils literal notranslate"><span class="pre">RTE_LCORE_MAX</span></code>), kept in a static array. A DPDK application may
reuse the same pattern, to good effect.</p>
<p>Since DPDK worker threads are pinned to CPU core, and no more than one
worker thread uses a particular core, the per-thread data structure
effectively become a per DPDK lcore data structure.</p>
<p>The DPDK lcore id, numbered from 0 to <code class="docutils literal notranslate"><span class="pre">RTE_LCORE_MAX-1</span></code>, is then
used as a index into the array of instances. The lcore id may be
retrieved relatively cheaply with <code class="docutils literal notranslate"><span class="pre">rte_lcore_id()</span></code>.</p>
<p>If the per-core data structures are large, it’s better to have an
array of pointers, and only allocated as many as the actual lcore
count, or dynamically on-demand. This will reduce the amount of memory
used, and allow allocation from <a class="reference internal" href="../glossary.html#term-Huge-Pages"><span class="xref std std-term">huge page</span></a> memory.</p>
<p>This scheme disallows modifying counters from non-lcore worker
threads, but does allow read operations from any thread (even such
that my be preempted).</p>
<p>A data plane application have the option of reusing this pattern
for its own per-core data structures. It may also choose to use
Thread Local Storage (TLS) directly, instead</p>
<p>The example code for this approach uses the same data model and very
similar struct definition as <a class="reference internal" href="#shared-non-synchronized-counters"><span class="std std-ref">Shared Non Synchronized Counters</span></a>.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#define EP_MAX_SESSIONS (1000)</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="n">sessions</span><span class="p">[</span><span class="n">EP_MAX_SESSIONS</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="n">__rte_cache_aligned</span><span class="p">;</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="n">lcore_stats</span><span class="p">[</span><span class="n">RTE_MAX_LCORE</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">__rte_cache_aligned</span></code> attribute is crucial from a
performance perspective. If left out, the data structures for two
different cores may wholly, or in part, reside on the same cache
line (i.e., <a class="reference internal" href="../glossary.html#term-False-sharing"><span class="xref std std-term">false sharing</span></a>). If frequently-updated counters for
two different cores are hosted by the same cache line, this shared
cache line will partly defeat the purpose of using per-core data
structures. <em>False sharing</em> does not impact correctness.</p>
</div>
<section id="id25">
<h4>Arithmetic Operations<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h4>
<p>Since the statistics are duplicated across all lcores, no
lcore-to-lcore writer synchronization is required.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"></span>
<span class="nf">stats_add64</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="o">*</span><span class="n">counter_value</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">operand</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">new_value</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">new_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">counter_value</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">operand</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="n">__atomic_store_n</span><span class="p">(</span><span class="n">counter_value</span><span class="p">,</span><span class="w"> </span><span class="n">new_value</span><span class="p">,</span><span class="w"> </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lcore_id</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="o">*</span><span class="n">stats</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">lcore_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rte_lcore_id</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="n">stats</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lcore_stats</span><span class="p">[</span><span class="n">lcore_id</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="n">stats_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">total_pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">stats_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">total_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="n">stats_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">stats_add64</span><span class="p">(</span><span class="o">&amp;</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">,</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="id26">
<h4>Reading<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h4>
<p>To retrieve the value of a counter, a reader needs to take a sum over
all instances of that counter, in all the per-core statistics structs.</p>
<p>A reader may choose to either iterate over all possible lcores (i.e.,
from 0 up to <code class="docutils literal notranslate"><span class="pre">RTE_LCORE_MAX</span></code>) , or just those actually in use (e.g.,
using the <code class="docutils literal notranslate"><span class="pre">RTE_LCORE_FOREACH</span></code> macro from <code class="docutils literal notranslate"><span class="pre">rte_lcore.h</span></code>). The
read-side operation is usually not very performance sensitive, so it
makes sense to do whatever results in the cleanest code.</p>
<p>Here’s an example, which provides per-counter API.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"></span>
<span class="nf">stats_get_lcore_total_bytes</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lcore_id</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="o">*</span><span class="n">stats</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lcore_stats</span><span class="p">[</span><span class="n">lcore_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="n">__atomic_load_n</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">total_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">__ATOMIC_RELAXED</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">uint64_t</span><span class="w"></span>
<span class="nf">ep_stats_get_total_bytes</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lcore_id</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">lcore_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">lcore_id</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RTE_LCORE_MAX</span><span class="p">;</span><span class="w"> </span><span class="n">lcore_ide</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">		</span><span class="n">total_bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stats_get_lcore_total_bytes</span><span class="p">(</span><span class="n">lcore_id</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="n">total_bytes</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>To guarantee that the counter is read atomically (e.g., so that a
64-bit counter is not read with two 32-bit loads), an atomic load
should be used. Non-atomic loads (on the level of the ISA) from
naturally aligned data is always atomic on all contemporary
architectures, and the compiler rarely has a reason to break up the
load into several instructions. However, there is no reason not to use
an atomic load, from a performance perspective.</p>
<p>Atomic loads with the <code class="docutils literal notranslate"><span class="pre">__ATOMIC_RELAXED</span></code> memory model does not
require memory barriers on any architectures. It does however imply
that loads of different variables may be reordered. Thus, if <code class="docutils literal notranslate"><span class="pre">pkts</span></code>
is read before <code class="docutils literal notranslate"><span class="pre">bytes</span></code> in the program’s source, the compiler and/or
the processor may choose to reorder those load operations, so that
<code class="docutils literal notranslate"><span class="pre">bytes</span></code> is read before <code class="docutils literal notranslate"><span class="pre">pkts</span></code>. Usually this is not a problem for
counters, but see the discussion on transactions and consistency.</p>
<p>In the unlikely case atomicity would be violated, the results may be
disastrous from a correctness point of view. For example, consider a
64-bit counter that currently has the value 4294967295 (FFFFFFFF in
hexadecimal). Just as the counter is being read by some control plane
thread, it’s also being incremented by one by the owning lcore worker
thread. If the lcore worker store, or the control plane load operation
fail to be atomic, the read may read the least significant 32 bits
from the old value, and the most significant 32 bits from the new
value. What the control plane thread will see is neither 4294967295,
nor 4294967296, but 8589934591.</p>
<p>This phenomena is known as load or store <em>tearing</em>.</p>
</section>
<section id="id27">
<h4>Inter Counter Consistency<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h4>
<p>The atomic store used by the counter producer thread (e.g., the lcore
worker) is only atomic for a particular counter, and the statistics
may be in a transient state of inconsistency, seen over a set of
different counters, for a short period of time.</p>
<p>For example, if a 1000-byte EP packet is processed, the reader may see
a <code class="docutils literal notranslate"><span class="pre">bytes</span></code> counter where that packet is accounted for, but a <code class="docutils literal notranslate"><span class="pre">pkts</span></code>
which is not yet updated. Similarly, it may read an updated
<code class="docutils literal notranslate"><span class="pre">total_bytes</span></code>, but a not-yet-updated session-level <code class="docutils literal notranslate"><span class="pre">bytes</span></code>
counter.</p>
<p>Provided the lcore worker thread is not preempted by the operating
system (which should only very rarely happen in a correctly configured
deployment), the time window of the counters being inconsistency is
likely to be very short indeed, but not zero-sized.  If the counters
are updated at a very high rate, the risk for a reader of seeing some
inconsistencies might still be considerable.</p>
<p>The counter state will converge toward a consistent state. This is
often enough, but for application where it is not, and the efficiency
of the per-core counter approach is still required, adding one or more
<a class="reference internal" href="../glossary.html#term-Sequence-counter"><span class="xref std std-term">sequence counters</span></a> to protect the
statistics data may be an option.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#define EP_MAX_SESSIONS (1000)</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="n">rte_seqcount_t</span><span class="w"> </span><span class="n">sc</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="n">sessions</span><span class="p">[</span><span class="n">EP_MAX_SESSIONS</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_bytes</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">total_pkts</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="n">__rte_cache_aligned</span><span class="p">;</span><span class="w"></span>

<span class="k">static</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="n">lcore_stats</span><span class="p">[</span><span class="n">RTE_LCORE_MAX</span><span class="p">];</span><span class="w"></span>

<span class="kt">void</span><span class="w"></span>
<span class="nf">ep_stats_update</span><span class="p">(</span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lcore_id</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_stats</span><span class="w"> </span><span class="o">*</span><span class="n">stats</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">lcore_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rte_lcore_id</span><span class="p">();</span><span class="w"></span>

<span class="w">	</span><span class="n">stats</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">lcore_stats</span><span class="p">[</span><span class="n">lcore_id</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_seqcount_begin_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">sc</span><span class="p">);</span><span class="w"></span>

<span class="w">	</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">total_pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">total_bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">pkt_size</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="n">rte_seqcount_end_write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="o">-&gt;</span><span class="n">sc</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>In this solution, the neither the loads nor the stores need be atomic,
since the sequence counter guarantees atomicity over the whole set of
counters.</p>
<p>The introduction of a sequence counter will increase the statistics
overhead, both on the reader, and more importantly, writer side. The
sequence counter requires incrementing a sequence number twice, and a
number of memory barriers. On a Total Store Order (TSO) <a class="reference internal" href="../glossary.html#term-ISA"><span class="xref std std-term">ISA</span></a>
(e.g., AMD64/IA-64), only an inexpensive compiler barrier is
needed. On a weakly ordered CPU (e.g. ARM), actual barrier
instructions are required.</p>
<p>The reader side will look something like:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">uint64_t</span><span class="w"></span>
<span class="nf">ep_stats_get_session_stats</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">session_id</span><span class="p">,</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">stats</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="k">struct</span><span class="w"> </span><span class="nc">ep_session_stats</span><span class="w"> </span><span class="o">*</span><span class="n">session_stats</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">		</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">.</span><span class="n">sessions</span><span class="p">[</span><span class="n">session_id</span><span class="p">];</span><span class="w"></span>
<span class="w">	</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">sn</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="k">do</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">		</span><span class="n">sn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rte_seqcount_read_begin</span><span class="p">(</span><span class="o">&amp;</span><span class="n">config</span><span class="o">-&gt;</span><span class="n">sc</span><span class="p">);</span><span class="w"></span>

<span class="w">		</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">pkts</span><span class="p">;</span><span class="w"></span>
<span class="w">		</span><span class="n">result</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session_stats</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">;</span><span class="w"></span>

<span class="w">	</span><span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">rte_seqcount_read_retry</span><span class="p">(</span><span class="o">&amp;</span><span class="n">config</span><span class="o">-&gt;</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="n">sn</span><span class="p">));</span><span class="w"></span>

<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="n">total_bytes</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>This pattern represents an unorthodox use of a sequence counter, which
is normally used to protect data which changes relatively
infrequently. One issue that may occur, is that the reader will have
to retry many times, known as reader starvation, since the data keeps
changing while it’s being read.</p>
<p>Another option to achieve inter counter consistency is to protect the
per-core statistics structure, or structures, with one or more
spinlocks. Since a writer would only contend with a reader for such a
lock, the level of contentions will be very low, and thus the overhead
to acquire the lock will be as well.</p>
</section>
<section id="id28">
<h4>Performance<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h4>
<p>Keeping per-core instances of statistics data structures is generally
the most CPU cycle-efficient way to implement counters.</p>
<p>Add a sequence counter or a spinlock to improve consistency adds
overhead, but from what the <a class="reference internal" href="#performance-comparison"><span class="std std-ref">micro benchmarks</span></a> suggests, it is very small. <a class="footnote-reference brackets" href="#ignorantauthor" id="id29">6</a></p>
<p>The largest threat to the viability of the <a class="reference internal" href="#per-core-counters"><span class="std std-ref">Per Core Counters</span></a>
approach is space efficiency. The amount of statistics memory grows
linearly with the lcore worker count. This is not an issue in cases
where the amount of statistics is relatively small. For systems
supporting hundreds of thousands or even millions of flows, per-flow
counters are kept, and flows are migrated across different lcore
workers, this approach may prevent the fast path from utilizing many
CPU cores, especially on memory-constrained systems.</p>
</section>
</section>
<section id="performance-comparison">
<span id="id30"></span><h3>Performance Comparison<a class="headerlink" href="#performance-comparison" title="Permalink to this headline">¶</a></h3>
<p>The relative performance of the different approaches to counter
implementation varies with a number of factors.</p>
<ul class="simple">
<li><p>Counter update frequency, which in turn is usually depend on the
per-packet processing latency.</p></li>
<li><p>Counter <a class="reference internal" href="../glossary.html#term-Working-set-size"><span class="xref std std-term">working set size</span></a> (i.e., the number of counters
modified).</p></li>
<li><p>The amount of overlap between two or more cores’ counter working set.</p></li>
<li><p>Worker core count.</p></li>
<li><p>CPU implementation details (e.g., memory model and cache latency).</p></li>
</ul>
<p>The benchmarking application simulates a fairly low-touch data plane
application, spending ~1000 clock cycles/packet for domain logic
processing (thus excluding packet I/O). No actual packets are sent,
and the clock cycles spent are dummy calculations, not using any
memory. The numbers measured represent how much the application is
slowed down, when statistics is added. Latency is specified as an
average over all counter add operations.</p>
<p>The counter implementations in the benchmark are identical to the
examples.</p>
<p>The application modifies two global counters, and two flow-related
counters per packet. How many counters are incremented per packet, and
how many are related to a flow, and how many are global as opposed to
per-flow (or the equivalent), varies wildly between applications. This
benchmark is at the low end of counter usage.</p>
<p>In the benchmark, load balancing of packets over cores works in such a
way, that packet pertaining to a particular flow hits the same core,
unless it’s migrated to another core. Migrations happens very rarely.
The DSW Event Device is the <a class="reference internal" href="../glossary.html#term-Work-scheduler"><span class="xref std std-term">work scheduler</span></a> used to distribute
the packets. This means there is almost no contention for the cache
lines hosting the two flow-related counters for each of the 1024 flows
in the test.</p>
<p>A real application would likely make heavy use of the level 1 and
level 2 CPU caches, and thus the below numbers are an underestimation
of the actual overhead.</p>
<p>The counters are updated all-in-one-go. In a real application however,
different counters (or sets of counters) will be incremented at
different stages of processing. This makes a difference for the
sequence counter and spinlock-based approaches, in the benchmark the
overhead for the locking/unlocking is amortized over four counter
updates (i.e., the lock is only taken once). In some applications, the
lock may need to be acquired for every counter update, and thus many
times for a single packet.</p>
<section id="system-under-test-hardware">
<h4>System under Test Hardware<a class="headerlink" href="#system-under-test-hardware" title="Permalink to this headline">¶</a></h4>
<p>The “Cascade Lake Xeon” is a server with a 20-core Intel Xeon Gold
6230N CPU. To improve determinism, the Intel Turbo function is disabled,
and all CPU cores run the nominal clock frequency - 2,3 GHz. The
compiler used is GCC 10.3.0.</p>
<p>The “BCM2711 ARM A72” is a Raspberry Pi 4. It is equipped with a
Broadcom BCM2711 SoC, with four ARM Cortex-A72 cores operating at 1,5
GHz. The code is compiled with GCC 9.3.0.</p>
<p>As expected, the variant based sequence counter-based synchronization
suffers somewhat from the weakly ordered memory model requirements’
for barrier instructions.  Surprisingly, on the BCM2711, the per-core
spinlock variant performs as well as the per-core variant which only
uses atomic stores - a fact which the author find difficult to
explain.</p>
<p>DPDK 22.07 was used for both systems.</p>
<p>In both the Raspberry Pi and Xeon server case, the test
application and DPDK was compiled with``-O3 -march=native``.</p>
</section>
<section id="benchmark-results">
<h4>Benchmark Results<a class="headerlink" href="#benchmark-results" title="Permalink to this headline">¶</a></h4>
<p>The counter update overhead is expressed in CPU core cycles.</p>
<table class="docutils align-default" id="id32">
<caption><span class="caption-text">Per-counter Update Overhead</span><a class="headerlink" href="#id32" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>CPU</p></th>
<th class="head"><p>Worker Core Count</p></th>
<th class="head"><p>Shared No Sync</p></th>
<th class="head"><p>Shared Spinlock</p></th>
<th class="head"><p>Shared Atomics</p></th>
<th class="head"><p>Shared Buffered</p></th>
<th class="head"><p>Per Core</p></th>
<th class="head"><p>Per Core Spinlock</p></th>
<th class="head"><p>Per Core Seqcount</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Cascade Lake Xeon</p></td>
<td><p>4</p></td>
<td><p>27</p></td>
<td><p>436</p></td>
<td><p>56</p></td>
<td><p>18</p></td>
<td><p>5</p></td>
<td><p>7</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd"><td><p>Cascade Lake Xeon</p></td>
<td><p>20</p></td>
<td><p>273</p></td>
<td><p>8236</p></td>
<td><p>626</p></td>
<td><p>18</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td><p>BCM2711 ARM A72</p></td>
<td><p>4</p></td>
<td><p>26</p></td>
<td><p>36</p></td>
<td><p>85</p></td>
<td><p>24</p></td>
<td><p>4</p></td>
<td><p>4</p></td>
<td><p>8</p></td>
</tr>
</tbody>
</table>
<p>The different benchmark programs use the various implements the
various patterns described earlier in this chapter, in a manner very
similar to the example code.</p>
<table class="colwidths-given docutils align-default" id="id33">
<caption><span class="caption-text">Benchmark Counter Implementation Descriptions</span><a class="headerlink" href="#id33" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Test case name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Shared No Sync</p></td>
<td><p><a class="reference internal" href="#shared-non-synchronized-counters"><span class="std std-ref">Shared Non Synchronized Counters</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>Shared Spinlock</p></td>
<td><p><a class="reference internal" href="#shared-lock-protected-counters"><span class="std std-ref">Shared Lock Protected Counters</span></a></p></td>
</tr>
<tr class="row-even"><td><p>Shared Buffered</p></td>
<td><p><a class="reference internal" href="#shared-counters-with-per-core-buffering"><span class="std std-ref">Shared Counters with Per Core Buffering</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>Per Core</p></td>
<td><p>The atomic store variant described in <a class="reference internal" href="#per-core-counters"><span class="std std-ref">Per Core Counters</span></a></p></td>
</tr>
<tr class="row-even"><td><p>Per Core Spinlock</p></td>
<td><p>The spinlock-protected per core statistics struct variant
described in <a class="reference internal" href="#per-core-counters"><span class="std std-ref">Per Core Counters</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>Per Core Seqcount</p></td>
<td><p>The sequence counter-protected per core statistics struct
variant described in <a class="reference internal" href="#per-core-counters"><span class="std std-ref">Per Core Counters</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="device-statistics">
<h2>Device Statistics<a class="headerlink" href="#device-statistics" title="Permalink to this headline">¶</a></h2>
</section>
<section id="metrics-library">
<h2>Metrics Library<a class="headerlink" href="#metrics-library" title="Permalink to this headline">¶</a></h2>
</section>
<section id="telemetry-library">
<h2>Telemetry Library<a class="headerlink" href="#telemetry-library" title="Permalink to this headline">¶</a></h2>
<p class="rubric">Footnotes</p>
<dl class="footnote brackets">
<dt class="label" id="cyclesvslogic"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>The reverse is not necessarily true. For example, applications that
copy, encrypt or decrypt the packet payload will have generally
have high processing latency, but not at the cost of increased
domain logic complexity or more counter updates.</p>
</dd>
<dt class="label" id="sleep"><span class="brackets"><a class="fn-backref" href="#id9">2</a></span></dt>
<dd><p>Exceptions are, among other, some energy efficiency-related scenarios.</p>
</dd>
<dt class="label" id="id31"><span class="brackets"><a class="fn-backref" href="#id13">3</a></span></dt>
<dd><p>It’s unclear to the author what is the appropriate semantics
for the flow reset should be, in regards to global counters.
E.g., should the flow’s packets be deducted from <code class="docutils literal notranslate"><span class="pre">total_pkts</span></code>?</p>
</dd>
<dt class="label" id="nogain"><span class="brackets"><a class="fn-backref" href="#id22">4</a></span></dt>
<dd><p>The author’s experience is that the performance gains are slight indeed.</p>
</dd>
<dt class="label" id="nodemand"><span class="brackets"><a class="fn-backref" href="#id23">5</a></span></dt>
<dd><p>The reader might ask herself, why there is any demand at all to be
efficient in low-load situations, as long as you stay under 100%
CPU utilization. For traditional, always busy-polling DPDK-based
designs there may be none. However, if the fast path uses CPU power
management, remaining efficient at low load may allow the
application to put more worker lcores to sleep, or reduce to an
even lower core operating frequency, that it could have done
otherwise.</p>
</dd>
<dt class="label" id="ignorantauthor"><span class="brackets"><a class="fn-backref" href="#id29">6</a></span></dt>
<dd><p>The author does not have any practical experience with the use
spinlock-protected or sequence counter-protected <em>per-core</em>
statistics in real applications.</p>
</dd>
</dl>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Data Plane Software Design</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../threading.html">Threading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../work.html">Work Scheduling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../eth.html">Ethernet Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mbuf.html">The Packet Buffer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../headers.html">Protocol Header Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mem.html">Memory Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sync.html">Synchronization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cache.html">Caches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datastructures.html">Data Structures</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#counters">Counters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#organization">Organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synchronization">Synchronization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#device-statistics">Device Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metrics-library">Metrics Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="#telemetry-library">Telemetry Library</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../time.html">Timekeeping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../timers.html">Timers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../crypto.html">Cryptography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modularization.html">Modularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../control.html">Control Plane</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slowpath.html">Slow Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="../antipatterns.html">Anti Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../datastructures.html" title="previous chapter">Data Structures</a></li>
      <li>Next: <a href="../time.html" title="next chapter">Timekeeping</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Ericsson AB.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/stats/stats.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>